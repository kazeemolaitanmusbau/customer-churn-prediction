{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4692780d",
   "metadata": {},
   "source": [
    "### Model Summary: Customer Churn Prediction Using Decision Tree with Oversampling and PCA\n",
    "\n",
    "**Objective**: The goal of this project is to predict customer churn using a decision tree model that has been enhanced by oversampling the minority class (churned customers) and applying PCA for dimensionality reduction. The model aims to achieve better accuracy, precision, recall, and other classification metrics by addressing the class imbalance issue.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. Data Preprocessing**\n",
    "\n",
    "**Dataset Overview**:\n",
    "- The dataset contains various features related to customer interactions, service usage, and customer service calls.\n",
    "- **Target Variable**: `churn` (0 = no churn, 1 = churn)\n",
    "\n",
    "**Key Features**:\n",
    "- Customer account length, area code, international plan, voicemail plan, total day/evening/night calls and minutes, international calls and charges, number of customer service calls, etc.\n",
    "\n",
    "**Handling Imbalanced Data**:\n",
    "- **Class Distribution** (Before): The dataset was imbalanced, with significantly more non-churn (0) customers than churn (1) customers.\n",
    "- **Oversampling**: Applied Synthetic Minority Oversampling (SMOTE) technique to balance the number of churned (1) and non-churned (0) customers. The class distribution after oversampling:\n",
    "  - **Churn (1)**: 3652 instances\n",
    "  - **Non-Churn (0)**: 3652 instances\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Dimensionality Reduction (PCA)**\n",
    "\n",
    "To improve computational efficiency and reduce the risk of overfitting, **Principal Component Analysis (PCA)** was applied to transform the feature space. This step retained the most important components, reducing the dimensionality of the dataset while preserving key variance.\n",
    "\n",
    "- **PCA Benefits**: Reduced the complexity of the feature set, allowing the decision tree model to train more effectively and generalize better.\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Model Selection: Decision Tree**\n",
    "\n",
    "**Model Type**: Decision Tree Classifier\n",
    "- A decision tree was chosen due to its interpretability and ability to handle both categorical and numerical features.\n",
    "  \n",
    "**Tuning**: Hyperparameter tuning was performed on the decision tree model to improve its performance. Parameters such as `max_depth`, `min_samples_split`, and `min_samples_leaf` were optimized.\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Model Performance Evaluation**\n",
    "\n",
    "After training the decision tree model with the oversampled data and applying PCA, the following metrics were evaluated:\n",
    "\n",
    "- **Accuracy**: Overall ability of the model to correctly classify both churn and non-churn cases.\n",
    "- **Precision**: The proportion of positive identifications (churn) that were actually correct.\n",
    "- **Recall**: The ability of the model to find all relevant churn cases.\n",
    "- **F1-Score**: The harmonic mean of precision and recall, providing a single metric for both.\n",
    "- **ROC-AUC**: Assessed the model's ability to distinguish between churn and non-churn cases.\n",
    "\n",
    "**Performance Results**:\n",
    "- After handling the class imbalance and reducing dimensionality, the decision tree performed well, with a balanced evaluation across key metrics.\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Deployment Strategy**\n",
    "\n",
    "The decision tree model with **oversampling and PCA** will be deployed in a production environment. This model will be able to predict customer churn with a high level of accuracy and balance between precision and recall. \n",
    "\n",
    "**Next Steps**:\n",
    "- **Monitoring**: Regularly monitor the model's performance post-deployment to ensure that it remains accurate as new data arrives.\n",
    "- **Retraining**: Periodically retrain the model with updated data, especially if class distribution changes over time.\n",
    "- **Scaling**: Consider scaling the deployment to handle larger datasets or integrating it into a broader customer relationship management (CRM) system.\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "This decision tree model with oversampling and PCA is a well-tuned, balanced approach to predicting customer churn, and it is ready for deployment. It provides robust predictions and helps businesses focus on retaining customers who are at high risk of churning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37e936e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "                            accuracy_score,\n",
    "                            precision_score,\n",
    "                            recall_score,\n",
    "                            f1_score,\n",
    "                            roc_auc_score,\n",
    "                            confusion_matrix,\n",
    "                            classification_report,\n",
    "                            roc_curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e4f0fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20fba4ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     3652\n",
       "yes     598\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[\"churn\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63315c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                            0\n",
       "account_length                   0\n",
       "area_code                        0\n",
       "international_plan               0\n",
       "voice_mail_plan                  0\n",
       "number_vmail_messages            0\n",
       "total_day_minutes                0\n",
       "total_day_calls                  0\n",
       "total_day_charge                 0\n",
       "total_eve_minutes                0\n",
       "total_eve_calls                  0\n",
       "total_eve_charge                 0\n",
       "total_night_minutes              0\n",
       "total_night_calls                0\n",
       "total_night_charge               0\n",
       "total_intl_minutes               0\n",
       "total_intl_calls                 0\n",
       "total_intl_charge                0\n",
       "number_customer_service_calls    0\n",
       "churn                            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check missing values\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b1a0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check duplicates\n",
    "train.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8506b1",
   "metadata": {},
   "source": [
    "# Train the model with Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4576cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform all the category column \n",
    "le = LabelEncoder()\n",
    "train[\"state\"]= le.fit_transform(train[\"state\"])\n",
    "train=pd.get_dummies(train, columns=[\"area_code\", \"international_plan\",\"voice_mail_plan\" ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8d3be38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into feature and target\n",
    "X = train.copy()\n",
    "y = X.pop(\"churn\")\n",
    "# transform the label data\n",
    "rel = {\"no\":0, \"yes\":1}\n",
    "y=y.map(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49943c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f989a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into into train and val set\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76b8b8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc = DecisionTreeClassifier()\n",
    "model_1 = dc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cce1839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_pred = model_1.predict(val_x)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_proba = model_1.predict_proba(val_x)[:, 1]  # For binary classification, get probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a623c86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8952941176470588\n",
      "Precision: 0.6408450704225352\n",
      "Recall: 0.7054263565891473\n",
      "F1 Score: 0.6715867158671587\n",
      "ROC-AUC Score: 0.8173456332182907\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_y, y_pred)\n",
    "precision = precision_score(val_y, y_pred)\n",
    "recall = recall_score(val_y, y_pred)\n",
    "f1 = f1_score(val_y, y_pred)\n",
    "roc_auc = roc_auc_score(val_y, y_proba)  # Use predicted probabilities for ROC-AUC\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC-AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7ede0a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[670  51]\n",
      " [ 38  91]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_y, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d87e05ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       721\n",
      "           1       0.64      0.71      0.67       129\n",
      "\n",
      "    accuracy                           0.90       850\n",
      "   macro avg       0.79      0.82      0.80       850\n",
      "weighted avg       0.90      0.90      0.90       850\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "report = classification_report(val_y, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dbcc9655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(val_y, y_proba)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d64e16",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Here’s a brief explanation of each metric:\n",
    "\n",
    "- **accuracy_score**: Calculates the accuracy of the model, which is the ratio of correctly predicted instances to the total number of instances.\n",
    "\n",
    "- **precision_score**: Measures the precision of the model, which is the ratio of true positive predictions to the sum of true positive and false positive predictions.\n",
    "\n",
    "- **recall_score**: Measures the recall of the model, which is the ratio of true positive predictions to the sum of true positive and false negative predictions.\n",
    "\n",
    "- **f1_score**: The harmonic mean of precision and recall. It balances the two metrics, especially useful when dealing with imbalanced classes.\n",
    "\n",
    "- **roc_auc_score**: Measures the area under the Receiver Operating Characteristic (ROC) curve, which evaluates the model’s ability to distinguish between positive and negative classes.\n",
    "\n",
    "- **confusion_matrix**: Provides a matrix showing the true positive, false positive, true negative, and false negative counts.\n",
    "\n",
    "- **classification_report**: Summarizes precision, recall, F1-score, and support for each class.\n",
    "\n",
    "- **roc_curve**: Computes the ROC curve, which plots the true positive rate against the false positive rate at various thresholds.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703da0a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6acb8be9",
   "metadata": {},
   "source": [
    "# Train the model with Balanced Data After Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26875ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "majority_class=train.query(\"churn=='no'\")\n",
    "len_majority_class= len(majority_class)\n",
    "\n",
    "minority_class=train.query(\"churn=='yes'\")\n",
    "len_minority_class= len(minority_class)\n",
    "\n",
    "\n",
    "over_sample_set=resample(minority_class, n_samples=len_majority_class, random_state=42)\n",
    "train_=pd.concat([majority_class, over_sample_set], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "66c072d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into feature and target\n",
    "X = train_.copy()\n",
    "y = X.pop(\"churn\")\n",
    "rel = {\"no\":0, \"yes\":1}\n",
    "y=y.map(rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5fd5c079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3652\n",
       "1    3652\n",
       "Name: churn, dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8229a3",
   "metadata": {},
   "source": [
    "### Summary: Dataset After Oversampling\n",
    "\n",
    "After applying oversampling, the class distribution in the dataset has become perfectly balanced:\n",
    "\n",
    "- **Class 0 (Non-churn)**: 3652 instances\n",
    "- **Class 1 (Churn)**: 3652 instances\n",
    "\n",
    "This balance ensures that the model is exposed to an equal number of samples from both classes, which helps in preventing bias towards the majority class (class `0` in this case). The oversampling technique has replicated samples from the minority class (class `1`) to match the number of instances in the majority class, resulting in:\n",
    "\n",
    "- **Balanced Class Distribution**: Both classes now have an equal number of 3652 instances, which improves the model’s ability to learn from both classes effectively.\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "1. **Improved Minority Class Performance**: With the oversampling of class `1`, the model will be better able to detect and correctly classify instances of churn (class `1`), which was previously underrepresented.\n",
    "   \n",
    "2. **Reduced Bias**: Models trained on imbalanced datasets tend to favor the majority class. By balancing the dataset, you reduce this bias, ensuring the model gives equal consideration to both classes during training.\n",
    "\n",
    "3. **Better Metrics**: Metrics such as **precision**, **recall**, and **F1-score** for the minority class (churn) should improve as the model is now better trained to recognize churn cases without being dominated by the majority class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "08c13289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into into train and val set\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e43ad6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc = DecisionTreeClassifier()\n",
    "model_2 = dc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "aaf93586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_pred = model_2.predict(val_x)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_proba = model_2.predict_proba(val_x)[:, 1]  # For binary classification, get probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0b738a8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9650924024640657\n",
      "Precision: 0.9365918097754293\n",
      "Recall: 0.9957865168539326\n",
      "F1 Score: 0.9652825051055139\n",
      "ROC-AUC Score: 0.9658505347954577\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_y, y_pred)\n",
    "precision = precision_score(val_y, y_pred)\n",
    "recall = recall_score(val_y, y_pred)\n",
    "f1 = f1_score(val_y, y_pred)\n",
    "roc_auc = roc_auc_score(val_y, y_proba)  # Use predicted probabilities for ROC-AUC\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC-AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "99e33dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[701  48]\n",
      " [  3 709]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_y, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bfbd7e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.96       749\n",
      "           1       0.94      1.00      0.97       712\n",
      "\n",
      "    accuracy                           0.97      1461\n",
      "   macro avg       0.97      0.97      0.97      1461\n",
      "weighted avg       0.97      0.97      0.97      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "report = classification_report(val_y, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24fd35f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e32655e9",
   "metadata": {},
   "source": [
    "# Train the Model with Balanced Data and on Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348bbc64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "87a9d71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "anal = PCA(n_components=15)\n",
    "new_col = anal.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "363ec7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into into train and val set\n",
    "train_x, val_x, train_y, val_y = train_test_split(new_col, y, random_state=42, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a529e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training the model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dc = DecisionTreeClassifier()\n",
    "model_3 = dc.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "bfc29284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted values\n",
    "y_pred = model_3.predict(val_x)\n",
    "\n",
    "# Get predicted probabilities\n",
    "y_proba = model_3.predict_proba(val_x)[:, 1]  # For binary classification, get probabilities for the positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94319f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9698836413415469\n",
      "Precision: 0.9453333333333334\n",
      "Recall: 0.9957865168539326\n",
      "F1 Score: 0.969904240766074\n",
      "ROC-AUC Score: 0.9705234319917193\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy = accuracy_score(val_y, y_pred)\n",
    "precision = precision_score(val_y, y_pred)\n",
    "recall = recall_score(val_y, y_pred)\n",
    "f1 = f1_score(val_y, y_pred)\n",
    "roc_auc = roc_auc_score(val_y, y_proba)  # Use predicted probabilities for ROC-AUC\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC-AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "970ebcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[708  41]\n",
      " [  3 709]]\n"
     ]
    }
   ],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(val_y, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "99eeef9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.95      0.97       749\n",
      "           1       0.95      1.00      0.97       712\n",
      "\n",
      "    accuracy                           0.97      1461\n",
      "   macro avg       0.97      0.97      0.97      1461\n",
      "weighted avg       0.97      0.97      0.97      1461\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "report = classification_report(val_y, y_pred)\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c714d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8cf1f1c",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "\n",
    "1. **Imbalanced Data**: The dataset is imbalanced with more instances of class `0` (majority class) than class `1` (minority class).\n",
    "2. **Balanced Data After Oversampling**: Oversampling has been used to balance the classes.\n",
    "3. **Balanced Data with Feature Selection**: Feature selection has been applied after balancing the data.\n",
    "\n",
    "### Analysis\n",
    "\n",
    "#### **1. Imbalanced Data**\n",
    "\n",
    "- **Precision (0)**: 0.95\n",
    "- **Precision (1)**: 0.65\n",
    "- **Recall (0)**: 0.93\n",
    "- **Recall (1)**: 0.72\n",
    "- **Accuracy**: 0.90\n",
    "\n",
    "Here, the model performs well for class `0` with high precision and recall, but the performance on class `1` is lower. The precision for class `1` is 0.65, which means there are more false positives, and the recall of 0.72 indicates it misses several positive instances.\n",
    "\n",
    "#### **2. Balanced Data After Oversampling**\n",
    "\n",
    "- **Precision (0)**: 0.94\n",
    "- **Precision (1)**: 0.98\n",
    "- **Recall (0)**: 0.99\n",
    "- **Recall (1)**: 0.94\n",
    "- **Accuracy**: 0.96\n",
    "\n",
    "After oversampling, the model improves significantly on class `1` performance. Precision for class `1` is now 0.98, and recall is 0.94. The high recall for class `0` (0.99) suggests the model has almost no false negatives. The overall accuracy of 0.96 is much higher than in the imbalanced case.\n",
    "\n",
    "#### **3. Balanced Data with Feature Selection**\n",
    "\n",
    "- **Precision (0)**: 1.00\n",
    "- **Precision (1)**: 0.95\n",
    "- **Recall (0)**: 0.95\n",
    "- **Recall (1)**: 1.00\n",
    "- **Accuracy**: 0.97\n",
    "\n",
    "After balancing and feature selection, the model’s performance improves further. Precision and recall for class `1` are nearly perfect, and the precision for class `0` reaches 1.00. This indicates that the model is now more capable of distinguishing between the two classes and performs better on the minority class.\n",
    "\n",
    "### Recommendations\n",
    "\n",
    "1. **Handling Imbalance**: The model trained on the imbalanced data struggles with the minority class (class `1`). If class `1` represents a critical business outcome (e.g., customer churn), it’s essential to address this imbalance before training the model. Techniques like **oversampling** or **undersampling** can help improve performance.\n",
    "\n",
    "2. **Oversampling Benefits**: The oversampling technique has greatly enhanced the model’s ability to predict the minority class. The improved recall (0.94) and precision (0.98) for class `1` show that the model is now identifying more true positives and reducing false positives.\n",
    "\n",
    "3. **Feature Selection**: After performing feature selection, the model's overall performance improved further. This suggests that certain features may have been irrelevant or redundant, and removing them helped the model generalize better. You should consider **recursive feature elimination (RFE)** or other feature selection techniques to identify the most important features.\n",
    "\n",
    "4. **Next Steps**: \n",
    "   - **Hyperparameter Tuning**: To further enhance the model, tune the hyperparameters (e.g., max depth, min samples split) for the decision tree.\n",
    "   - **Other Classifiers**: Consider comparing the decision tree performance to other models like **Random Forest** or **Gradient Boosting**.\n",
    "   - **Evaluation Metrics**: Since you are dealing with imbalanced classes, keep focusing on metrics like **precision, recall, and F1-score** instead of accuracy alone. Also, **ROC-AUC** should be part of the evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e22a9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62388f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2530902b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
